{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Transfer Learning On A2D2\n",
    "This notebook creates datasets for the Incremental Transfer Learning approach described in [Abdou et. al](https://arxiv.org/pdf/1906.10964.pdf). The code blocks below are only meant to be examples of how this dataset can be manipulated into sub-datasets, but please feel free to use them if you find them helpful!\n",
    "\n",
    "Please note that you may have to modify paths in the functions and scripts below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "pkl_file = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_start_0_stop_10000_COMBINED_CLASSES.pkl\")\n",
    "with open(pkl_file, \"rb\") as f:\n",
    "    D = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "keys = list(D.keys())\n",
    "\n",
    "# Stage 1\n",
    "labels_map_stage_1 = {0: 0, 1: 0, 2: 0, 3: 3, 4: 0, 5: 0} \n",
    "labels_stage_1 = {} \n",
    "for key in keys:\n",
    "    labels_stage_1[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_1[key].append(labels_map_stage_1[label])\n",
    "pkl_out_file_stage_1 = os.path.join(os.getcwd(), \"data\", \"stage_1_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_1, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_1, f)\n",
    "    f.close()\n",
    "    \n",
    "# Stage 2\n",
    "labels_map_stage_2 = {0: 0, 1: 0, 2: 0, 3: 3, 4: 4, 5: 0}\n",
    "labels_stage_2 = {} \n",
    "for key in keys:\n",
    "    labels_stage_2[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_2[key].append(labels_map_stage_2[label])\n",
    "pkl_out_file_stage_2 = os.path.join(os.getcwd(), \"data\", \"stage_2_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_2, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_2, f)\n",
    "    f.close()\n",
    "    \n",
    "# Stage 3\n",
    "labels_map_stage_3 = {0: 0, 1: 0, 2: 0, 3: 3, 4: 4, 5: 5}\n",
    "labels_stage_3 = {} \n",
    "for key in keys:\n",
    "    labels_stage_3[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_3[key].append(labels_map_stage_3[label])\n",
    "pkl_out_file_stage_3 = os.path.join(os.getcwd(), \"data\", \"stage_3_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_3, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_3, f)\n",
    "    f.close()\n",
    "\n",
    "# Stage 4\n",
    "labels_map_stage_4 = {0: 0, 1: 0, 2: 2, 3: 3, 4: 4, 5: 5}\n",
    "labels_stage_4 = {} \n",
    "for key in keys:\n",
    "    labels_stage_4[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_4[key].append(labels_map_stage_4[label])\n",
    "pkl_out_file_stage_4 = os.path.join(os.getcwd(), \"data\", \"stage_4_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_4, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_4, f)\n",
    "    f.close()\n",
    "    \n",
    "# Stage 5\n",
    "labels_map_stage_5 = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n",
    "labels_stage_5 = {} \n",
    "for key in keys:\n",
    "    labels_stage_5[key] = []\n",
    "    labels = D[key]['labels']\n",
    "    for label in labels:\n",
    "        labels_stage_5[key].append(labels_map_stage_5[label])\n",
    "pkl_out_file_stage_5 = os.path.join(os.getcwd(), \"data\", \"stage_5_labels.pkl\")\n",
    "# Now write new labels to output\n",
    "with open(pkl_out_file_stage_5, \"wb\") as f:\n",
    "    pickle.dump(labels_stage_5, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Different-Staged Datasets\n",
    "Creating .pkl files for classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_combined = {0:\"other\", 1:\"road\", 2:\"car\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\"}\n",
    "pkl_out_file = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_COMBINED.pkl\")\n",
    "print(pkl_out_file)\n",
    "with open(pkl_out_file, \"wb\") as f:\n",
    "    pickle.dump(classes_combined, f)\n",
    "    f.close()\n",
    "    \n",
    "classes_road_detection = {0:\"non-road\", 1:\"road\"}\n",
    "pkl_out_file_road = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_ROAD_DETECTION.pkl\")\n",
    "with open(pkl_out_file_road, \"wb\") as f:\n",
    "    pickle.dump(classes_road_detection, f)\n",
    "    f.close()\n",
    "\n",
    "# Write for Stage 1\n",
    "classes_stage_1 = {0:\"other\", 3:\"pedestrian\"}\n",
    "pkl_out_file_stage_1 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_1.pkl\")\n",
    "with open(pkl_out_file_stage_1, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_1, f)\n",
    "    f.close()\n",
    "\n",
    "# Write for Stage 2\n",
    "classes_stage_2 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\"}\n",
    "pkl_out_file_stage_2 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_2.pkl\")\n",
    "with open(pkl_out_file_stage_2, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_2, f)\n",
    "    f.close()\n",
    "\n",
    "# Write for Stage 3\n",
    "classes_stage_3 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\"}\n",
    "pkl_out_file_stage_3 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_3.pkl\")\n",
    "with open(pkl_out_file_stage_3, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_3, f)\n",
    "    f.close()\n",
    "    \n",
    "# Write for Stage 4\n",
    "classes_stage_4 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\", 2:\"car\"}\n",
    "pkl_out_file_stage_4 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_4.pkl\")\n",
    "with open(pkl_out_file_stage_4, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_4, f)\n",
    "    f.close()\n",
    "    \n",
    "# Write for Stage 5\n",
    "classes_stage_5 = {0:\"other\", 3:\"pedestrian\", 4:\"road signs/signals\", 5:\"lanes\", 2:\"car\", 1:\"road\"}\n",
    "pkl_out_file_stage_5 = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary_STAGE_5.pkl\")\n",
    "with open(pkl_out_file_stage_5, \"wb\") as f:\n",
    "    pickle.dump(classes_stage_5, f)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
