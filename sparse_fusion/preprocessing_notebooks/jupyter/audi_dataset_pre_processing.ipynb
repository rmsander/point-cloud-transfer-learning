{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [A2D2](https://www.a2d2.audi/a2d2/en.html) Preprocessing In Python\n",
    "This notebook outlines the preprocessing steps used to process the A2D2 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Block\n",
    "Standard libraries for computer vision and 3D point sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import json\n",
    "import pickle\n",
    "import pptk\n",
    "from pyntcloud import PyntCloud\n",
    "import pptk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "The functions below are utility functions designed for path manipulation, point cloud conversions, and manipulating the underlying semantic classes of the objects considered in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary from hex --> RGB for classes\n",
    "def hex2rgb(hex_id):\n",
    "    hex_id = hex_id[1:]\n",
    "    return tuple(int(hex_id[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# Iterate through all GT semantic images, and find all unique RGB triplets for class values.\n",
    "def make_semantic_mask_dict(seg_img_dir):\n",
    "    imgs = os.listdir(seg_img_dir)\n",
    "    color_triplets = set()\n",
    "    for img in imgs:\n",
    "        A_label = cv.imread(img)\n",
    "        img_triplets = np.unique(img.reshape(-1, img.shape[2]), axis=0)\n",
    "        color_triplets.update(img_triplets)\n",
    "\n",
    "# Convert classes to ID numbers\n",
    "def get_classes_to_ids(json_file=os.path.join(os.getcwd(), \"data\", \\\n",
    "                                              \"camera_lidar_semantic\", \"class_list.json\")):\n",
    "    with open(json_file) as file:\n",
    "        hex_dict = json.load(file)\n",
    "        file.close()\n",
    "\n",
    "    class_dict = {}\n",
    "    rgb_dict = {}\n",
    "    inverse_rgb_dict = {}\n",
    "\n",
    "    j = 0\n",
    "    for key in list(hex_dict.keys()):\n",
    "        class_dict[j] = hex_dict[key]\n",
    "        rgb_dict[hex2rgb(key)] = j\n",
    "        inverse_rgb_dict[j] = hex2rgb(key)\n",
    "        j += 1\n",
    "    \n",
    "    # Pickle these files once we're ready\n",
    "    dict_save = os.path.join(os.getcwd(), \"data\", \"camera_lidar_semantic\", \"class_dictionary.pkl\")\n",
    "    with open(dict_save, \"wb\") as f:\n",
    "        pickle.dump([class_dict, rgb_dict], f)\n",
    "        f.close()\n",
    "    print(\"FILES PICKLED\")\n",
    "    return class_dict, rgb_dict\n",
    "\n",
    "# Function for pickling files\n",
    "def pickle_file(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "        f.close()\n",
    "    print(\"Object pickled to file located at {}\".format(path))\n",
    "    \n",
    "# Function for loading pickle files\n",
    "def load_pickle_file(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "        f.close()\n",
    "    print(\"Object loaded from file located at {}\".format(path))\n",
    "    return dataset\n",
    "\n",
    "# Function from A2D2 tutorial used for importing images\n",
    "def extract_image_file_name_from_lidar_file_name(file_name_lidar):\n",
    "    # Manipulate string path\n",
    "    file_name_image = file_name_lidar.split('/')\n",
    "    file_name_image = file_name_image[-1].split('.')[0]\n",
    "    file_name_image = file_name_image.split('_')\n",
    "    file_name_image = file_name_image[0] + '_' + \\\n",
    "                        'camera_' + \\\n",
    "                        file_name_image[2] + '_' + \\\n",
    "                        file_name_image[3] + '.png'\n",
    "\n",
    "    return file_name_image\n",
    "\n",
    "# Finally, let's create a function for merging all of this data, and pickle this file to be saved\n",
    "def create_and_export_data(start_indices = [i*2000 for i in range(0, 14)], \\\n",
    "                           stop_indices = [i*2000 for i in range(1, 15)]):\n",
    "    for start, stop in zip(start_indices, stop_indices):\n",
    "        Dataset = merge_data(start_index=start, stop_index=stop)\n",
    "        print(\"Processed indices from {} to {}\".format(start, stop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Point Cloud Data\n",
    "Utility function for displaying point cloud data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_point_cloud(tuple,seg_label=[],title=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if seg_label == []:\n",
    "        x = [x[0] for x in tuple]\n",
    "        y = [y[1] for y in tuple]\n",
    "        z = [z[2] for z in tuple]\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.scatter(x, y, z, c='b', cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    else:\n",
    "        category = list(np.unique(seg_label))\n",
    "        color = ['b','r','g','y','w','b','p']\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        for categ_index in range(len(category)):\n",
    "            tuple_seg = tuple[seg_label == category[categ_index]]\n",
    "            x = [x[0] for x in tuple_seg]\n",
    "            y = [y[1] for y in tuple_seg]\n",
    "            z = [z[2] for z in tuple_seg]\n",
    "            ax.scatter(x, y, z, c=color[categ_index], cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Merging\n",
    "The full semantic segmentation dataset has over 55 semantic classes, with severe class imbalance. In this project, I considered baseline approaches by reducing the number of classes from >55 to 6 (see the dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading and merging data\n",
    "COMBINED_CLASSES = {'road': [32, 40, 44, 42, 50, 27, 40, 42, 44, 50], \\\n",
    "                    'car': [0, 1, 2, 3, 11, 12, 13, 14, 15, 16, 23, 24, 46], \\\n",
    "                    'pedestrian': [4, 5, 6, 7, 8, 9, 10], \\\n",
    "                    'road signs/signals': [17, 18, 19, 20, 21, 22], \\\n",
    "                    'lanes': [28, 47, 48, 49]}\n",
    "\n",
    "def merge_data(start_index=None, stop_index=None, combine_classes=False):\n",
    "    \"\"\"Function for merging classes, i.e. to reduce the total number of classes in the dataset.\n",
    "    Recommended for running baseline tests, such as road segmentation.\"\"\"\n",
    "    # Get current working directory and data folder\n",
    "    CWD = os.getcwd()\n",
    "    data_folder = os.path.join(CWD, \"data\",\"camera_lidar_semantic\")\n",
    "    \n",
    "\n",
    "    # Get classes <--> labels dictionaries\n",
    "    class_dict, rgb_dict = get_classes_to_ids()\n",
    "    \n",
    "    if combine_classes:\n",
    "        combined_classes = COMBINED_CLASSES\n",
    "    \n",
    "    # Get folders which we will recursively scrape from to aggregate data\n",
    "    sub_folders = os.listdir(data_folder)\n",
    "    sub_folders_all_dir = [sub_folder for sub_folder in sub_folders if \\\n",
    "                    os.path.isdir(os.path.join(data_folder,sub_folder))]\n",
    "    sub_folders_filtered = [sub_folder for sub_folder in sub_folders_all_dir if \\\n",
    "              \"lidar\" in os.listdir(os.path.join(data_folder,sub_folder)) and\n",
    "              \"label\" in os.listdir(os.path.join(data_folder,sub_folder)) and\n",
    "              \"camera\" in os.listdir(os.path.join(data_folder,sub_folder))]\n",
    "\n",
    "    # Get IDs for iterating through each (image, label, point cloud) triple\n",
    "    IDs = set()\n",
    "    for sub_folder in sub_folders_filtered:\n",
    "        sub_data_dir = os.path.join(data_folder, sub_folder,\"camera\",\"cam_front_center\")\n",
    "        files = os.listdir(sub_data_dir)\n",
    "        file_IDs = [file.split(\"_\")[0]+\"_\"+file.split(\"_\")[-1].split(\".\")[0] for file in files]\n",
    "        IDs.update(file_IDs)\n",
    "\n",
    "    print(\"Number of IDs in dataset: {}\".format(len(list(IDs))))\n",
    "\n",
    "    # Initialize empty dataset and counter\n",
    "    Dataset = {}\n",
    "    i = 0\n",
    "    \n",
    "    if start_index is None:\n",
    "        start_index = 0\n",
    "    if stop_index is None:\n",
    "        stop_index = len(IDs)\n",
    "    print(\"START index is {}, STOP index is {}\".format(start_index, stop_index))\n",
    "    # Iterate over point clouds, rgb, and labels\n",
    "    for ID in list(IDs)[start_index:stop_index]:\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Iterated through {} files\".format(i))\n",
    "        # Get ID information\n",
    "        ID_split = ID.split(\"_\")\n",
    "        ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "        \n",
    "        # Get directories for each individual set of images, labels, and point clouds\n",
    "        ind_data_dir = os.path.join(data_folder, ID_split[0][:-6]+\"_\"+ID_split[0][-6:])\n",
    "        ind_pc_dir = os.path.join(ind_data_dir, \"lidar\", \"cam_front_center\")\n",
    "        ind_label_dir = os.path.join(ind_data_dir, \"label\", \"cam_front_center\")\n",
    "        ind_camera_dir = os.path.join(ind_data_dir, \"camera\", \"cam_front_center\")\n",
    "        \n",
    "        # Get filenames for images, labels, and point clouds\n",
    "        pc_file_name =  ID_split[0]+\"_lidar_frontcenter_\"+ID_split[1]+\".npz\"\n",
    "        label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "        camera_file_name = ID_split[0]+\"_camera_frontcenter_\"+ID_split[1]+\".png\"\n",
    "        \n",
    "        # Load images, labels, and point clouds\n",
    "        A_label = cv.imread(os.path.join(ind_label_dir, label_file_name))\n",
    "        A_camera = cv.imread(os.path.join(ind_camera_dir, camera_file_name))\n",
    "        pc = np.load(os.path.join(ind_pc_dir,pc_file_name), allow_pickle=True)\n",
    "        \n",
    "        # Give labels to points in PC equal to [row, index] these points map to in label image space\n",
    "        keys = list(pc.keys())\n",
    "        if 'row' in keys and 'col' in keys and 'points' in keys:\n",
    "            rows, cols = pc['row'], pc['col']\n",
    "            classes = []\n",
    "            rgb = []\n",
    "            N = len(rows)\n",
    "            for row, col in zip(rows, cols): # O(n)\n",
    "                rgb_data = A_camera[int(row), int(col), :][::-1]\n",
    "                rgb_label = tuple(A_label[int(row), int(col), :])[::-1]\n",
    "                \n",
    "                # 6 different classes\n",
    "                if combine_classes==\"six_classes\":\n",
    "                    if rgb_dict[rgb_label] in combined_classes['road']:\n",
    "                        classes.append(1)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['car']:\n",
    "                        classes.append(2)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['pedestrian']:\n",
    "                        classes.append(3)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['road signs/signals']:\n",
    "                        classes.append(4)\n",
    "                    elif rgb_dict[rgb_label] in combined_classes['lanes']:\n",
    "                        classes.append(5)\n",
    "                    else:\n",
    "                        classes.append(0)\n",
    "                \n",
    "                # MVP - Road Detector\n",
    "                elif combine_classes==\"road_detection\":\n",
    "                    if rgb_dict[rgb_label] in combined_classes['road']:\n",
    "                        classes.append(1)\n",
    "                    else:\n",
    "                        classes.append(0)\n",
    "                \n",
    "                # Create labels over all 55 classes\n",
    "                else:  \n",
    "                    classes.append(rgb_dict[rgb_label]) # O(1)\n",
    "                rgb.append(rgb_data)\n",
    "            classes = np.array(classes)\n",
    "            rgb = np.array(rgb).reshape((N, 3))\n",
    "            Dataset[ID] = {'points': pc['points'], 'labels': classes, 'rgb': rgb}\n",
    "        i += 1\n",
    "        pickle_outfile = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_{}_ids.pkl\".format(i))\n",
    "    if combined_classes == \"six_classes\":\n",
    "        pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_{}_stop_{}_COMBINED_CLASSES.pkl\".format(start_index, \\\n",
    "                                                                                                    stop_index))\n",
    "    elif combined_classes == \"road_detection\":\n",
    "        pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_{}_stop_{}_ROAD_DETECTION.pkl\".format(start_index, \\\n",
    "                                                                                                    stop_index))\n",
    "    else:\n",
    "         pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_{}_stop_{}.pkl\".format(start_index, stop_index))\n",
    "    with open(pickle_outfile, \"wb\") as f:\n",
    "        pickle.dump(Dataset, f)\n",
    "        f.close()\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Consistency Between RGB and Semantic Class ID\n",
    "The functions below ensure that semantic class IDs are properly mapped to their associated RGB values/point cloud returns following manipulation either by merging RGB with lidar xyz, or by merging the semantic classes of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rgb_id_consistency(Dataset):\n",
    "    dataset_pickle = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera.pkl\")\n",
    "    with open(dataset_pickle, \"wb\") as f:\n",
    "        pickle.dump(Dataset, f)\n",
    "        f.close()\n",
    "\n",
    "    with open(dataset_pickle,\"rb\") as f:\n",
    "        D = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    keys = list(D.keys())[:len(keys)]\n",
    "    minidataset = {key: D[key] for key in keys}\n",
    "    for key in keys:\n",
    "        A_img = D[key]['rgb']\n",
    "        A_label = D[key]['rgb_labels']\n",
    "        print(A_img.shape, A_label.shape)\n",
    "        plt.imshow(A_img)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.imshow(A_label)\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "\n",
    "def test_id_consistency(D, index):\n",
    "    # Define and get IDs\n",
    "    ID = list(D.keys())[index]\n",
    "    labels_pc = D[ID][\"labels\"]\n",
    "    \n",
    "    # Current working directory and data directory\n",
    "    CWD = os.getcwd()\n",
    "    data_folder = os.path.join(CWD, \"data\",\"camera_lidar_semantic\")\n",
    "\n",
    "    # Get classes <--> labels dictionaries\n",
    "    class_dict, rgb_dict = get_classes_to_ids()\n",
    "    inverse_rgb_dict = {rgb_dict[key]:key for key in list(rgb_dict.keys())}\n",
    "    \n",
    "    # Split ID string for parsing below\n",
    "    ID_split = ID.split(\"_\")\n",
    "    ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "    print(\"ID is: {}, ID_split is: {}\".format(ID, ID_split))\n",
    "    \n",
    "    # Get paths for image, labels, and point clouds\n",
    "    ind_data_dir = os.path.join(data_folder, ID_split[0][:-6]+\"_\"+ID_split[0][-6:])\n",
    "    ind_pc_dir = os.path.join(ind_data_dir, \"lidar\", \"cam_front_center\")\n",
    "    ind_label_dir = os.path.join(ind_data_dir, \"label\", \"cam_front_center\")\n",
    "    ind_camera_dir = os.path.join(ind_data_dir, \"camera\", \"cam_front_center\")\n",
    "\n",
    "    # Get file names for image, labels, and point clouds\n",
    "    pc_file_name =  ID_split[0]+\"_lidar_frontcenter_\"+ID_split[1]+\".npz\"\n",
    "    label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "    camera_file_name = ID_split[0]+\"_camera_frontcenter_\"+ID_split[1]+\".png\"\n",
    "\n",
    "    # Load data for image, labels, and point clouds\n",
    "    A_label = cv.imread(os.path.join(ind_label_dir, label_file_name))\n",
    "    pc = np.load(os.path.join(ind_pc_dir,pc_file_name), allow_pickle=True)\n",
    "    print(pc)\n",
    "    A_camera = cv.imread(os.path.join(ind_camera_dir, camera_file_name))\n",
    "    \n",
    "    keys = list(pc.keys())\n",
    "    ID_split = ID.split(\"_\")\n",
    "    ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "    \n",
    "    # Give labels to points in PC equal to [row, index] these points map to in label image space \n",
    "    label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "    Img = os.path.join(ind_label_dir, label_file_name)\n",
    "    rows, cols = pc['row'], pc['col']\n",
    "    classes = []\n",
    "    rgb_labels = []\n",
    "    test_img = A_camera\n",
    "    for row, col, label in zip(rows, cols, labels_pc): # O(n)\n",
    "        rgb_data = A_camera[int(row), int(col), :][::-1]\n",
    "        rgb_label = tuple(A_label[int(row), int(col), :])[::-1]\n",
    "        classes.append(rgb_dict[rgb_label]) # O(1)\n",
    "        rgb_labels.append(rgb_label)\n",
    "        #test_img[int(row),int(col),:] = np.array(inverse_rgb_dict[label])\n",
    "        test_img[int(row),int(col),:] = rgb_data\n",
    "    print(\"TEST if zero (zero indicates correct behavior): {}\".format(\\\n",
    "                                np.sum(np.subtract(labels_pc, np.array(classes)))))\n",
    "    \n",
    "    # Display the point cloud\n",
    "    show_point_cloud(pc['points'],seg_label=classes)\n",
    "    \n",
    "    # Plot to qualitatively confirm results\n",
    "    plt.imshow(A_camera)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.imshow(A_label)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Now load dummy dataset\n",
    "    pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                                      \"dataset_pc_labels_camera_start_{}_stop_{}.pkl\".format(0, 3))\n",
    "\n",
    "    with open(pickle_outfile, \"rb\") as f:\n",
    "        A = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    keys = list(A.keys())\n",
    "    for key in keys:\n",
    "        CWD = os.getcwd()\n",
    "        data_folder = os.path.join(CWD, \"data\",\"camera_lidar_semantic\")\n",
    "        ID_split = key.split(\"_\")\n",
    "        ID_split[-1] = ID_split[-1].split(\".\")[0]\n",
    "\n",
    "        # Get paths for image, labels, and point clouds\n",
    "        ind_data_dir = os.path.join(data_folder, ID_split[0][:-6]+\"_\"+ID_split[0][-6:])\n",
    "        RGB = A[key]['rgb']\n",
    "        ind_camera_dir = os.path.join(ind_data_dir, \"camera\", \"cam_front_center\")\n",
    "        ind_pc_dir = os.path.join(ind_data_dir, \"lidar\", \"cam_front_center\")\n",
    "\n",
    "\n",
    "        pc_file_name =  ID_split[0]+\"_lidar_frontcenter_\"+ID_split[1]+\".npz\"\n",
    "        label_file_name = ID_split[0]+\"_label_frontcenter_\"+ID_split[1]+\".png\"\n",
    "        camera_file_name = ID_split[0]+\"_camera_frontcenter_\"+ID_split[1]+\".png\"\n",
    "\n",
    "        A_camera = cv.imread(os.path.join(ind_camera_dir, camera_file_name))\n",
    "        pc = np.load(os.path.join(ind_pc_dir,pc_file_name), allow_pickle=True)\n",
    "\n",
    "        # Give labels to points in PC equal to [row, index] these points map to in label image space\n",
    "        keys = list(pc.keys())\n",
    "        if 'row' in keys and 'col' in keys and 'points' in keys:\n",
    "            rows, cols = pc['row'], pc['col']\n",
    "            classes = []\n",
    "            rgb = []\n",
    "            N = len(rows)\n",
    "            i = 0\n",
    "            for row, col in zip(rows, cols): # O(n)\n",
    "                i += 1\n",
    "\n",
    "\n",
    "    # Get classes <--> labels dictionaries\n",
    "    class_dict, rgb_dict = get_classes_to_ids()\n",
    "    inverse_rgb_dict = {rgb_dict[key]:key for key in list(rgb_dict.keys())}\n",
    "\n",
    "    test_id_consistency(A,1)\n",
    "    # Now load dummy dataset\n",
    "    pickle_outfile = os.path.join(os.getcwd(), \"data\", \\\n",
    "                                      \"dataset_pc_labels_camera_start_{}_stop_{}.pkl\".format(0, 3))\n",
    "\n",
    "    with open(pickle_outfile, \"rb\") as f:\n",
    "        A = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    keys = list(A.keys())\n",
    "    for key in keys:\n",
    "        print(A[key]['rgb'].shape)\n",
    "        print(A[key]['labels'].shape)\n",
    "        print(A[key]['points'].shape)\n",
    "\n",
    "# Now run the test\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
